# -*- coding: utf-8 -*-
"""Decision Tree - EX at Home.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tSbhTCneRC6tA4MvQr84Tt1TWjqNC431
"""

import pandas as pd
import numpy as np
import seaborn as sns
pd.set_option('display.max_columns', None)



from sklearn.model_selection import train_test_split
data = pd.read_csv('Data/DATA/DECISION_TREE_TRAIN_DATA_3.csv', index_col='CUSTOMER_ID')
# X_test = pd.read_csv('drive/My Drive/Colab Notebooks/PAD_DATA/EmployeeAttrition/test.csv', index_col='EmployeeNumber')

X_raw, X_test = train_test_split(data,random_state=0,test_size=0.2)



# X_raw['RISK_GROUP'] = X_raw['RISK_GROUP'].apply(lambda x: 1 if x > 1 else 0)

y = X_raw.RISK_GROUP
X_full = X_raw.drop(columns=['RISK_GROUP'])

cols_cat = [x for x in X_full.columns if (X_full[x].dtypes=='object')]
cols_num = [x for x in X_full.columns if (X_full[x].dtypes!='object')]

print(X_full.shape)
X_full.head(10)
# y.head(10)

sns.pairplot(data=X_raw, hue='RISK_GROUP')

X_full[cols_num].corr()

sns.heatmap(X_full[cols_num].corr(),cmap="PiYG")

X_full_merge = pd.concat([X_full[cols_num],pd.get_dummies(data=X_full[cols_cat])],axis=1)
X_test_merge = pd.concat([X_test[cols_num],pd.get_dummies(data=X_test[cols_cat])],axis=1)
print(X_full_merge.shape)
X_full_merge.head(3)

X_full_merge.isnull().values.any()

X_full.describe()

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier


X_train, X_valid, y_train, y_valid = train_test_split(X_full_merge, y, random_state=0,test_size=0.3)

model_decisiontree = DecisionTreeClassifier(criterion="entropy", max_depth = 4, random_state = 0)




model_randomforest = RandomForestClassifier(criterion='entropy', max_depth=4, random_state=0,n_estimators=300)

model_decisiontree.fit(X_train, y_train)
model_randomforest.fit(X_train, y_train)

print('Decision Tree score: ' + str(model_decisiontree.score(X_valid, y_valid)))
print('Random forest score: ' + str(model_randomforest.score(X_valid, y_valid)))

import pickle


filename = 'model_decisiontree.sav'

# Fit the model on training set
model_decisiontree.fit(X_train, y_train)
pickle.dump(model_decisiontree, open(filename, 'wb'))
# load the model from disk
loaded_model = pickle.load(open(filename, 'rb'))
result = loaded_model.score(X_valid, y_valid)
print(result)

# feature importance
def drawFeatureImportance(model, title, n_top):
  importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(model.feature_importances_,3)})
  importances = importances.sort_values('importance',ascending=False).head(n_top)
  sns.barplot(y=importances['feature'],x=importances['importance']).set_title(title)

drawFeatureImportance(model_decisiontree, 'Decision Tree',12)

drawFeatureImportance(model_randomforest, 'Random forest',20)

from sklearn.externals.six import StringIO
from sklearn.tree import export_graphviz
import pydotplus
from IPython.display import Image

# draw tree
def drawTree(model):
  dot_data = StringIO()
  export_graphviz(model, out_file=dot_data,
                  filled=True, rounded=True,
                  special_characters=True,
                  feature_names = X_train.columns,
                  class_names=[str(x) for x in model.classes_]
                  )
  graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
  return graph.create_png()

Image(drawTree(model_decisiontree))

Image(drawTree(model_randomforest.estimators_[100]))

best_probs = [x for x in y_valid]
y_valid.shape



predict = model_randomforest.predict(X_test_merge)
predict = pd.DataFrame({'CUSTOMER_ID':X_test.index,'RISK_GROUP':predict})
predict = predict.merge(X_test,on='CUSTOMER_ID')
predict.head(3)

X_policy = X_valid.copy(True)
y_policy = model_randomforest.predict(X_policy)
y_policy = pd.DataFrame({'CUSTOMER_ID':X_policy.index,'RISK_GROUP':y_policy})
print(y_policy[y_policy.RISK_GROUP==1].shape)

y_policy[y_policy.RISK_GROUP==1]

X_policy = X_policy[X_policy.index.isin([253,311,340,91,0])]
X_policy
